{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION\n",
    "\n",
    "You've been contracted by Hyundai Heavy Industries to help them build a predictive model for some ships. Hyundai Heavy Industries is one of the world's largest ship manufacturing companies and builds cruise liners.\n",
    "\n",
    "You've been flown to their headquarters in Ulsan, South Korea to help them give accurate estimates of how many crew members a ship will require.\n",
    "\n",
    "They are currently building new ships for some customers and want you to create a model and use it to predict how many crew members the ships will need.\n",
    "\n",
    "Here is what the data looks like so far:\n",
    "\n",
    "Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "ships.\n",
    "\n",
    "\n",
    "Variables/Columns\n",
    "Ship Name     1-20\n",
    "Cruise Line   21-40\n",
    "Age (as of 2013)   46-48\n",
    "Tonnage (1000s of tons)   50-56\n",
    "passengers (100s)   58-64\n",
    "Length (100s of feet)  66-72\n",
    "Cabins  (100s)   74-80\n",
    "Passenger Density   82-88\n",
    "Crew  (100s)   90-96\n",
    "\n",
    "It is saved in a csv file for you called \"cruise_ship_info.csv\". Your job is to create a regression model that will help predict how many crew members will be needed for future ships. The client also mentioned that they have found that particular cruise lines will differ in acceptable crew counts, so it is most likely an important feature to include in your analysis! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/anshul/spark-3.0.0-preview2-bin-hadoop2.7/')\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('cruise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('cruise_ship_info.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
      "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
      "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
      "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
      "|      Glory|   Carnival| 10|             110.0|     29.74|  9.51| 14.87|            36.99|11.6|\n",
      "|    Holiday|   Carnival| 28|            46.052|     14.52|  7.27|  7.26|            31.72| 6.6|\n",
      "|Imagination|   Carnival| 18|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|Inspiration|   Carnival| 17|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|     Legend|   Carnival| 11|              86.0|     21.24|  9.63| 10.62|            40.49| 9.3|\n",
      "|   Liberty*|   Carnival|  8|             110.0|     29.74|  9.51| 14.87|            36.99|11.6|\n",
      "|    Miracle|   Carnival|  9|              88.5|     21.24|  9.63| 10.62|            41.67|10.3|\n",
      "|   Paradise|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|      Pride|   Carnival| 12|              88.5|     21.24|  9.63| 11.62|            41.67| 9.3|\n",
      "|  Sensation|   Carnival| 20|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making cruise_line a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      Cruise_line|count|\n",
      "+-----------------+-----+\n",
      "|          Azamara|    2|\n",
      "|         Carnival|   22|\n",
      "|        Celebrity|   10|\n",
      "|            Costa|   11|\n",
      "|          Crystal|    2|\n",
      "|           Cunard|    3|\n",
      "|           Disney|    2|\n",
      "| Holland_American|   14|\n",
      "|              MSC|    8|\n",
      "|        Norwegian|   13|\n",
      "|          Oceania|    3|\n",
      "|           Orient|    1|\n",
      "|              P&O|    6|\n",
      "|         Princess|   17|\n",
      "|Regent_Seven_Seas|    5|\n",
      "|  Royal_Caribbean|   23|\n",
      "|         Seabourn|    3|\n",
      "|        Silversea|    4|\n",
      "|             Star|    6|\n",
      "|         Windstar|    3|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing the Strings according to cruise_line counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer=StringIndexer(inputCol='Cruise_line',outputCol='Cruise_cat')\n",
    "indexed=indexer.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|Cruise_line|Cruise_cat|\n",
      "+-----------+----------+\n",
      "|    Azamara|      16.0|\n",
      "|    Azamara|      16.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "|   Carnival|       1.0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.select(['Cruise_line','Cruise_cat']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew',\n",
       " 'Cruise_cat']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include a feature column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combining the columns for a feature column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=['Age',\n",
    "             'Tonnage',\n",
    "             'passengers',\n",
    "             'length',\n",
    "             'cabins',\n",
    "             'passenger_density',\n",
    "             'Cruise_cat'],\n",
    " outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=assembler.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|crew|            features|\n",
      "+----+--------------------+\n",
      "|3.55|[6.0,30.276999999...|\n",
      "|3.55|[6.0,30.276999999...|\n",
      "| 6.7|[26.0,47.262,14.8...|\n",
      "|19.1|[11.0,110.0,29.74...|\n",
      "|10.0|[17.0,101.353,26....|\n",
      "| 9.2|[22.0,70.367,20.5...|\n",
      "| 9.2|[15.0,70.367,20.5...|\n",
      "| 9.2|[23.0,70.367,20.5...|\n",
      "| 9.2|[19.0,70.367,20.5...|\n",
      "|11.5|[6.0,110.23899999...|\n",
      "|11.6|[10.0,110.0,29.74...|\n",
      "| 6.6|[28.0,46.052,14.5...|\n",
      "| 9.2|[18.0,70.367,20.5...|\n",
      "| 9.2|[17.0,70.367,20.5...|\n",
      "| 9.3|[11.0,86.0,21.24,...|\n",
      "|11.6|[8.0,110.0,29.74,...|\n",
      "|10.3|[9.0,88.5,21.24,9...|\n",
      "| 9.2|[15.0,70.367,20.5...|\n",
      "| 9.3|[12.0,88.5,21.24,...|\n",
      "| 9.2|[20.0,70.367,20.5...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(['crew','features']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=output.select(['features','crew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[6.0,30.276999999...|3.55|\n",
      "|[6.0,30.276999999...|3.55|\n",
      "|[26.0,47.262,14.8...| 6.7|\n",
      "|[11.0,110.0,29.74...|19.1|\n",
      "|[17.0,101.353,26....|10.0|\n",
      "|[22.0,70.367,20.5...| 9.2|\n",
      "|[15.0,70.367,20.5...| 9.2|\n",
      "|[23.0,70.367,20.5...| 9.2|\n",
      "|[19.0,70.367,20.5...| 9.2|\n",
      "|[6.0,110.23899999...|11.5|\n",
      "|[10.0,110.0,29.74...|11.6|\n",
      "|[28.0,46.052,14.5...| 6.6|\n",
      "|[18.0,70.367,20.5...| 9.2|\n",
      "|[17.0,70.367,20.5...| 9.2|\n",
      "|[11.0,86.0,21.24,...| 9.3|\n",
      "|[8.0,110.0,29.74,...|11.6|\n",
      "|[9.0,88.5,21.24,9...|10.3|\n",
      "|[15.0,70.367,20.5...| 9.2|\n",
      "|[12.0,88.5,21.24,...| 9.3|\n",
      "|[20.0,70.367,20.5...| 9.2|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features| crew|\n",
      "+--------------------+-----+\n",
      "|[4.0,220.0,54.0,1...| 21.0|\n",
      "|[5.0,115.0,35.74,...| 12.2|\n",
      "|[5.0,122.0,28.5,1...|  6.7|\n",
      "|[5.0,133.5,39.59,...|13.13|\n",
      "|[5.0,160.0,36.34,...| 13.6|\n",
      "|[6.0,30.276999999...| 3.55|\n",
      "|[6.0,30.276999999...| 3.55|\n",
      "|[6.0,112.0,38.0,9...| 10.9|\n",
      "|[6.0,113.0,37.82,...| 12.0|\n",
      "|[6.0,158.0,43.7,1...| 13.6|\n",
      "|[7.0,89.6,25.5,9....| 9.87|\n",
      "|[7.0,116.0,31.0,9...| 12.0|\n",
      "|[7.0,158.0,43.7,1...| 13.6|\n",
      "|[8.0,77.499,19.5,...|  9.0|\n",
      "|[8.0,91.0,22.44,9...| 11.0|\n",
      "|[9.0,81.0,21.44,9...| 10.0|\n",
      "|[9.0,85.0,19.68,9...| 8.69|\n",
      "|[9.0,90.09,25.01,...| 8.69|\n",
      "|[9.0,105.0,27.2,8...|10.68|\n",
      "|[9.0,110.0,29.74,...| 11.6|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features| crew|\n",
      "+--------------------+-----+\n",
      "|[5.0,86.0,21.04,9...|  8.0|\n",
      "|[6.0,90.0,20.0,9....|  9.0|\n",
      "|[6.0,93.0,23.94,9...|11.09|\n",
      "|[6.0,110.23899999...| 11.5|\n",
      "|[8.0,110.0,29.74,...| 11.6|\n",
      "|[9.0,59.058,17.0,...|  7.4|\n",
      "|[9.0,88.5,21.24,9...| 10.3|\n",
      "|[9.0,116.0,26.0,9...| 11.0|\n",
      "|[10.0,138.0,31.14...|11.85|\n",
      "|[10.0,151.4,26.2,...|12.53|\n",
      "|[11.0,91.0,20.32,...| 9.99|\n",
      "|[11.0,91.62700000...|  9.0|\n",
      "|[11.0,108.977,26....| 12.0|\n",
      "|[12.0,25.0,3.88,5...| 2.87|\n",
      "|[12.0,88.5,21.24,...|10.29|\n",
      "|[12.0,88.5,21.24,...|  9.3|\n",
      "|[13.0,25.0,3.82,5...| 2.95|\n",
      "|[13.0,101.509,27....| 11.5|\n",
      "|[14.0,30.27699999...| 3.73|\n",
      "|[14.0,33.0,4.9,5....| 3.24|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              114|\n",
      "|   mean|7.745350877192993|\n",
      "| stddev|3.612161655117104|\n",
      "|    min|             0.59|\n",
      "|    max|             21.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|                44|\n",
      "|   mean| 7.920681818181819|\n",
      "| stddev|3.2411463646171605|\n",
      "|    min|              0.59|\n",
      "|    max|              13.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr=LinearRegression(labelCol='crew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model=lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficeint: [-0.01555702268214075,0.007079139583526512,-0.15188666072663484,0.3991276479779376,0.8842672872655041,-0.0019101453340354274,0.04146023672454371]\n",
      "intercept: -0.8479635422854516\n"
     ]
    }
   ],
   "source": [
    "print(\"coefficeint:\",lr_model.coefficients)\n",
    "print(\"intercept:\",lr_model.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9246416227553076\n",
      "MSE: 0.8549621305315686\n",
      "R2: 0.9167213238778045\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\",result.rootMeanSquaredError)\n",
    "print(\"MSE:\",result.meanSquaredError)\n",
    "print(\"R2:\",result.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|corr(crew, passengers)|\n",
      "+----------------------+\n",
      "|    0.9152341306065384|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('crew','passengers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|corr(crew, cabins)|\n",
      "+------------------+\n",
      "|0.9508226063578497|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('crew','cabins')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
